파일 준비(pandas)
```python
import pandas as pd

#csv 파일 읽어오기
wine=pd.read_csv("https://bit.ly/wine_csv_data")
#처음 5개의 데이터 출력하기
print(wine.head())
```

       alcohol  sugar    pH  class
    0      9.4    1.9  3.51    0.0
    1      9.8    2.6  3.20    0.0
    2      9.8    2.3  3.26    0.0
    3      9.8    1.9  3.16    0.0
    4      9.4    1.9  3.51    0.0
    
<br/>

데이터 셋 검사
```python
#모든 데이터에서 누락된 값이 있는지 검사
wine.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 6497 entries, 0 to 6496
    Data columns (total 4 columns):
     #   Column   Non-Null Count  Dtype  
    ---  ------   --------------  -----  
     0   alcohol  6497 non-null   float64
     1   sugar    6497 non-null   float64
     2   pH       6497 non-null   float64
     3   class    6497 non-null   float64
    dtypes: float64(4)
    memory usage: 203.2 KB
    

:::info 값이 누락된다면?
1. 평균값으로 누락된 값을 채우기
2. 해당 값을 버리고 사용하기

* 어떤 방식이 최선인지는 미리 알기 어려움
* 평균 값으로 변환 시, 훈련 세트의 평균으로 테스트 세트를 채워야 한다.
:::

<br/>

통계 출력
```python
#열에 대한 간단한 통계 출력
print(wine.describe())
```

               alcohol        sugar           pH        class
    count  6497.000000  6497.000000  6497.000000  6497.000000
    mean     10.491801     5.443235     3.218501     0.753886
    std       1.192712     4.757804     0.160787     0.430779
    min       8.000000     0.600000     2.720000     0.000000
    25%       9.500000     1.800000     3.110000     1.000000
    50%      10.300000     3.000000     3.210000     1.000000
    75%      11.300000     8.100000     3.320000     1.000000
    max      14.900000    65.800000     4.010000     1.000000
    

> 숫자들의 폭이 큰 것으로 보아 각 값들에 대한 scale이 다른 것을 확인 -> 표준화 진행

:::info n사분위수란?
    * 데이터를 순서대로 4등분한 n번째 값
    > ex 2사분위수: 데이터의 정중앙 값
    > 
    > 만약 데이터의 중간값이 두 개라면 평균값을 사용
    * 위의 25%(1사분위수), 50%(중간값, 2사분위수), 75%(3사분위수)가 이에 해당
:::

<br/>

데이터 프레임 넘파이 배열 변환
```python
#데이터 프레임의 3개 열을 넘파이 배열로 바꿈
data=wine[['alcohol', 'sugar', 'pH']].to_numpy()
#target데이터를 데이터 프레임에서 얻기
target=wine['class'].to_numpy()
```
<br/>

테스트 세트, 훈련 세트 만들기
```python
from sklearn.model_selection import train_test_split

#test_size: default는 0.25(25%), 이 값에 따라 테스트 세트를 분류함
train_input, test_input, train_target, test_target=train_test_split(data, target, test_size=0.2, random_state=42)
#전체 데이터의 80%, 20%

print(train_input.shape, test_input.shape)
```

    (5197, 3) (1300, 3)
    
<br/>

데이터 표준화
```python
from sklearn.preprocessing import StandardScaler

#데이터 표준화
ss=StandardScaler()
ss.fit(train_input)
train_scaled=ss.transform(train_input)
test_scaled=ss.transform(test_input)
```

<br/>

로지스틱 회귀를 이용한 모델 평가
```python
from sklearn.linear_model import LogisticRegression

lr=LogisticRegression()
lr.fit(train_scaled, train_target)
print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))
```

    0.7808350971714451
    0.7776923076923077
    
<br/>

학습된 계수와 절편 확인
```python
#계수와 절편 출력
print(lr.coef_, lr.intercept_)
```

    [[ 0.51270274  1.6733911  -0.68767781]] [1.81777902]
    
<br/>

결정 트리를 이용한 학습
```python
#결정 트리 클래스
from sklearn.tree import DecisionTreeClassifier

#이전 알고리즘과 사용법은 동일
dt=DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)
#과대적합
print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
```

    0.996921300750433
    0.8592307692307692
    
<br/>

트리의 결과 확인하기
```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(10, 7))
plot_tree(dt)
plt.show()
```


    
![png](5-_files/5-_12_0.png)
    

<br/>

filled된 깊이 1의 Tree 확인하기
```python
plt.figure(figsize=(10, 7))
#max_depth: 루트 노드 이후 한 개만 출력, filled: 클래스에 맞게 노드 색칠, feature_names: 특성의 이름 전달
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```


    
![png](5-_files/5-_13_0.png)
    


:::info 노드의 구성
1. 테스트 조건(sugar) - 이 조건으로 왼쪽 노드/ 오른쪽 노드를 판별(지니 불순도로부터 결정됨)
2. 불순도(gini)
3. 총 샘플 수(samples) - 해당 노드의 총 샘플 수
4. 클래스 별 샘플 수(value) - 조건으로 나누어진 두 클래스

* 노드의 색깔: 어떤 한 클래스의 비율이 더 많아질수록 색깔이 진해짐
* 두 클래스 사이의 개수를 비교하여 더 많은 쪽으로 결정함(위의 예시에서는 왼쪽, 오른쪽 둘 다 양성으로 분류할 것)

* gini 불순도 = $1-(음성 클래스 비율^2 + 양성 클래스 비율^2)$
* 0.5: 최악의 불순도(샘플의 클래스 비율이 정확히 일치 -> 구분이 잘 안되었다는 뜻)
:::
:::info 트리의 노드를 나누는 방법
* 결정 트리 모델은 부모 노드와 자식 노드의 불순도 차이가 가능한 한 크게 성장시킴

* 결정 트리 모델의 노드를 나누는 방식
* 정보 이득이 최대가 되도록 데이터를 나눔
* 정보 이득: $부모 불순도-(왼쪽 자식 샘플 수/부모 샘플 수)*왼쪽 자식 불순도 - (오른쪽 자식 샘플 수/부모 샘플 수)*오른쪽 자식 불순도$
* 정보 이득이 최대가 되는 테스트 조건의 값을 정한다
:::

<br/>

트리의 깊이 조정
```python
#앞의 트리는 깊이의 제한이 없었기 때문에 과대적합
#그러므로 깊이를 3으로 지정함(일반화)
dt=DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_scaled, train_target)
print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
```

    0.8454877814123533
    0.8415384615384616
    
<br/>

깊이 3인 트리의 그래프
```python
#깊이 3인 그래프
#여러 특성을 이용하고 있음(당도 , 알코올, 산도)
plt.figure(figsize=(20, 15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```


    
![png](5-_files/5-_17_0.png)
    

> 해석: 당도가 -0.802보다 크고 -0.239보다 작은 와인 중 알코올 도수가 0.454와 같거나 작으면 레드 와인으로 추측(붉은색 노드)

<br/>

표준화되지 않은 데이터의 학습
```python
#표준화되지 않은 데이터로 학습 후 평가(이전과 같음)
dt=DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_input, train_target)
print(dt.score(train_input, train_target))
print(dt.score(test_input, test_target))
```

    0.8454877814123533
    0.8415384615384616
    
:::info 표준화가 필요 없는 이유
* 결정 트리 알고리즘은 특성값의 스케일에 영향을 받지 않는다.
* 불순도를 클래스별 비율을 갖고 계산하며, 각 특성들은 따로 비교하기 때문
:::

<br/>

그래프 확인
```python
#표준화되지 않은 값으로 학습한 트리 알고리즘
plt.figure(figsize=(20, 15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```


    
![png](5-_files/5-_21_0.png)
    
<br/>

특성의 중요도 출력
```python
#구분에 필요한 특성의 중요도를 나타냄(알코올, 당도, pH)
print(dt.feature_importances_)
```

    [0.12345626 0.86862934 0.0079144 ]
    
